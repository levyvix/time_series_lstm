{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/MSFT.csv\")\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.set_index(\"Date\")\n",
    "data = data.diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_date = data.index[-1]\n",
    "\n",
    "# # Create a 2-week offset\n",
    "# offset = timedelta(weeks=2)\n",
    "\n",
    "# start = '2009-05-08'\n",
    "# end = last_date-offset\n",
    "\n",
    "# dataframe = data.copy()\n",
    "# dataframe = dataframe.loc[start:end, :]\n",
    "# dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(start, end=None):\n",
    "    last_date = data.index[-1]\n",
    "    offset = timedelta(weeks=2)\n",
    "\n",
    "    dataframe = data.copy()\n",
    "    if not end:\n",
    "        end = last_date-offset\n",
    "\n",
    "    dataframe = dataframe.loc[start:end, :]\n",
    "    return dataframe.rename(columns = {'Closing_Price': 'Close'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_data('2009-05-08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = scaler.fit_transform(train_set['Close'].values.reshape(-1,1))\n",
    "\n",
    "# how many days do i want to base my predictions on ?\n",
    "prediction_days = 60\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for x in range(prediction_days, len(scaled_data)):\n",
    "    x_train.append(scaled_data[x - prediction_days:x, 0])\n",
    "    y_train.append(scaled_data[x, 0])\n",
    "    \n",
    "x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(units = 50, return_sequences = True, input_shape = (x_train.shape[1],1)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50, return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units = 50))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 60, 50)            10400     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 60, 50)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 60, 50)            20200     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 60, 50)            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import RootMeanSquaredError\n",
    "\n",
    "model = LSTM_model()\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 1: val_loss improved from inf to 0.01205, saving model to ../model\\weights_best.hdf5\n",
      "85/85 [==============================] - 9s 50ms/step - loss: 0.0191 - val_loss: 0.0121\n",
      "Epoch 2/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0036\n",
      "Epoch 2: val_loss improved from 0.01205 to 0.01192, saving model to ../model\\weights_best.hdf5\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 0.0036 - val_loss: 0.0119\n",
      "Epoch 3/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0031\n",
      "Epoch 3: val_loss did not improve from 0.01192\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0031 - val_loss: 0.0120\n",
      "Epoch 4/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0029\n",
      "Epoch 4: val_loss did not improve from 0.01192\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0029 - val_loss: 0.0121\n",
      "Epoch 5/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 5: val_loss did not improve from 0.01192\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0028 - val_loss: 0.0121\n",
      "Epoch 6/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 6: val_loss did not improve from 0.01192\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0028 - val_loss: 0.0120\n",
      "Epoch 7/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0028\n",
      "Epoch 7: val_loss improved from 0.01192 to 0.01188, saving model to ../model\\weights_best.hdf5\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0028 - val_loss: 0.0119\n",
      "Epoch 8/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 8: val_loss improved from 0.01188 to 0.01184, saving model to ../model\\weights_best.hdf5\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 0.0026 - val_loss: 0.0118\n",
      "Epoch 9/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0026\n",
      "Epoch 9: val_loss did not improve from 0.01184\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0026 - val_loss: 0.0121\n",
      "Epoch 10/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0025\n",
      "Epoch 10: val_loss improved from 0.01184 to 0.01178, saving model to ../model\\weights_best.hdf5\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 0.0025 - val_loss: 0.0118\n",
      "Epoch 11/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0024\n",
      "Epoch 11: val_loss did not improve from 0.01178\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 0.0024 - val_loss: 0.0118\n",
      "Epoch 12/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0024\n",
      "Epoch 12: val_loss did not improve from 0.01178\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 0.0024 - val_loss: 0.0119\n",
      "Epoch 13/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0022\n",
      "Epoch 13: val_loss improved from 0.01178 to 0.01176, saving model to ../model\\weights_best.hdf5\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 0.0022 - val_loss: 0.0118\n",
      "Epoch 14/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0022\n",
      "Epoch 14: val_loss did not improve from 0.01176\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.0022 - val_loss: 0.0121\n",
      "Epoch 15/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0022\n",
      "Epoch 15: val_loss did not improve from 0.01176\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 0.0022 - val_loss: 0.0119\n",
      "Epoch 16/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0021\n",
      "Epoch 16: val_loss did not improve from 0.01176\n",
      "85/85 [==============================] - 3s 33ms/step - loss: 0.0021 - val_loss: 0.0118\n",
      "Epoch 17/25\n",
      "84/85 [============================>.] - ETA: 0s - loss: 0.0022\n",
      "Epoch 17: val_loss did not improve from 0.01176\n",
      "85/85 [==============================] - 3s 34ms/step - loss: 0.0022 - val_loss: 0.0122\n",
      "Epoch 18/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0021\n",
      "Epoch 18: val_loss improved from 0.01176 to 0.01174, saving model to ../model\\weights_best.hdf5\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.0021 - val_loss: 0.0117\n",
      "Epoch 19/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0019\n",
      "Epoch 19: val_loss did not improve from 0.01174\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.0019 - val_loss: 0.0118\n",
      "Epoch 20/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0020\n",
      "Epoch 20: val_loss improved from 0.01174 to 0.01173, saving model to ../model\\weights_best.hdf5\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.0020 - val_loss: 0.0117\n",
      "Epoch 21/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0020\n",
      "Epoch 21: val_loss improved from 0.01173 to 0.01173, saving model to ../model\\weights_best.hdf5\n",
      "85/85 [==============================] - 3s 36ms/step - loss: 0.0020 - val_loss: 0.0117\n",
      "Epoch 22/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0018\n",
      "Epoch 22: val_loss did not improve from 0.01173\n",
      "85/85 [==============================] - 3s 36ms/step - loss: 0.0018 - val_loss: 0.0118\n",
      "Epoch 23/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0018\n",
      "Epoch 23: val_loss did not improve from 0.01173\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.0018 - val_loss: 0.0119\n",
      "Epoch 24/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0018\n",
      "Epoch 24: val_loss did not improve from 0.01173\n",
      "85/85 [==============================] - 3s 35ms/step - loss: 0.0018 - val_loss: 0.0118\n",
      "Epoch 25/25\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.0018\n",
      "Epoch 25: val_loss did not improve from 0.01173\n",
      "85/85 [==============================] - 3s 36ms/step - loss: 0.0018 - val_loss: 0.0118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16d6ef6f1c0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath = '../model/weights_best.hdf5', \n",
    "                               verbose = 1, \n",
    "                               save_best_only = True)\n",
    "\n",
    "\n",
    "history = model.fit(x_train, \n",
    "          y_train, \n",
    "          validation_split=0.2,\n",
    "          epochs=25, \n",
    "          batch_size = 32,\n",
    "          callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "last_date = data.index[-1]\n",
    "offset = timedelta(weeks=2)\n",
    "\n",
    "test_data = load_data(start = last_date - offset,\n",
    "                      end = last_date)\n",
    "\n",
    "actual_prices = test_data['Close'].values\n",
    "\n",
    "total_dataset = pd.concat((data['Close'], test_data['Close']), axis=0)\n",
    "\n",
    "model_inputs = total_dataset[len(total_dataset) - len(test_data) - prediction_days:].values\n",
    "model_inputs = model_inputs.reshape(-1,1)\n",
    "model_inputs = scaler.transform(model_inputs)\n",
    "\n",
    "x_test = [\n",
    "    model_inputs[x - prediction_days : x, 0]\n",
    "    for x in range(prediction_days, len(model_inputs))\n",
    "]\n",
    "x_test = np.array(x_test)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1] ,1))\n",
    "\n",
    "predicted_prices = model.predict(x_test)\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31246108],\n",
       "       [-0.28739554],\n",
       "       [-0.26632956],\n",
       "       [-0.25694317],\n",
       "       [-0.26507357],\n",
       "       [-0.2821271 ],\n",
       "       [-0.29732755],\n",
       "       [-0.3063639 ],\n",
       "       [-0.3045134 ],\n",
       "       [-0.29149806]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# validade model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m test_loss, test_rmse \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(x_test, y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "# validade model\n",
    "\n",
    "test_loss, test_rmse = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_model\n",
    "\n",
    "import numpy as np\n",
    "#features = [Open, High, Low]\n",
    "features = np.array([[177.089996, 180.419998, 177.070007]])\n",
    "model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot test and prediction\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "fig = go.Figure([\n",
    "    go.Scatter(x=X_train.squeeze(), y=y_train, name='train', mode='markers'),\n",
    "    go.Scatter(x=X_test.squeeze(), y=y_test, name='test', mode='markers'),\n",
    "    go.Scatter(x=x_range, y=y_range, name='prediction')\n",
    "])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c394b73b62344de6585b1fbf0173cdea8a33e1dddaf0345fcb29b43abe6be766"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
